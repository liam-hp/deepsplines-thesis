{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeed.profiling.flops_profiler import get_model_profile\n",
    "from utils import calc_bspline_flops\n",
    "from models import LinearReLU\n",
    "from models import LinearBSpline\n",
    "import linspline\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def profile_model(arch, layers, ctrl=3, range_=1, input_size=8, batch_size=10):\n",
    "\n",
    "    if(arch == \"ReLU\"):\n",
    "        model = LinearReLU(layers)\n",
    "    elif(arch == \"BSpline\"):\n",
    "        model = LinearBSpline(layers, ctrl, range_)\n",
    "    elif(arch == \"LSpline\"):\n",
    "        model = linspline.LSplineFromBSpline(LinearBSpline(layers, ctrl, range_).get_layers())\n",
    "\n",
    "    base_flops, macs, params = get_model_profile(model=model, # model\n",
    "            input_shape=(batch_size, input_size), # input shape to the model. If specified, the model takes a tensor with this shape as the only positional argument.\n",
    "            args=None, # list of positional arguments to the model.\n",
    "            kwargs=None, # dictionary of keyword arguments to the model.\n",
    "            print_profile=False, #! prints the model graph with the measured profile attached to each module\n",
    "            detailed=True, # print the detailed profile\n",
    "            module_depth=-1, # depth into the nested modules, with -1 being the inner most modules\n",
    "            top_modules=1, # the number of top modules to print aggregated profile\n",
    "            warm_up=10, # the number of warm-ups before measuring the time of each module\n",
    "            as_string=True, # print raw numbers (e.g. 1000) or as human-readable strings (e.g. 1k)\n",
    "            output_file=None, # path to the output file. If None, the profiler prints to stdout.\n",
    "            ignore_modules=None) # the list of modules to ignore in the profiling\n",
    "    \n",
    "    flops = float(base_flops.replace(\"K\", \"\").strip()) * 1000 / batch_size\n",
    "\n",
    "    if(arch == \"BSpline\"):\n",
    "        flops += calc_bspline_flops(model)\n",
    "\n",
    "    housing = fetch_california_housing()\n",
    "    input = torch.tensor(housing.data, dtype=torch.float32)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    _ = model(input) # model output is irrelevant\n",
    "    end_time = time.perf_counter()\n",
    "    fwd_lat = (end_time - start_time) * 1000 * 1000 / len(input) # per sample latency: seconds -> microsec per input\n",
    "    fwd_lat = round(fwd_lat, 4)\n",
    "\n",
    "    return flops, params, fwd_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+---------------+------------+\n",
      "| Model           |   Params |   FLOPs/input |   μs/input |\n",
      "+=================+==========+===============+============+\n",
      "| ReLU [24, 8]    |      425 |           816 |     0.0604 |\n",
      "+-----------------+----------+---------------+------------+\n",
      "| BSpline [24, 8] |      521 |          1936 |     0.2434 |\n",
      "+-----------------+----------+---------------+------------+\n",
      "| LSpline [24, 8] |      425 |           784 |     0.5252 |\n",
      "+-----------------+----------+---------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from tabulate import tabulate\n",
    "\n",
    "print(\"FLOPS may be inaccurate for LSpline\")\n",
    "print(\"LSpline params should prob just be = bspline params\")\n",
    "\n",
    "archs_layers = [\n",
    "    # (\"ReLU\", [8]),\n",
    "    # (\"ReLU\", [24, 8]),\n",
    "    # (\"ReLU\", [24, 48, 24, 8]),\n",
    "    # (\"ReLU\", [24, 48, 96, 24, 8]),\n",
    "\n",
    "    # (\"BSpline\", [8]),\n",
    "    # (\"BSpline\", [24, 8]),\n",
    "    # (\"BSpline\", [24, 48, 24, 8]),\n",
    "    # (\"BSpline\", [24, 48, 96, 24, 8]),\n",
    "\n",
    "    # (\"LSpline\", [8]),\n",
    "    # (\"LSpline\", [24, 8]),\n",
    "    # (\"LSpline\", [24, 48, 24, 8]),\n",
    "    # (\"LSpline\", [24, 48, 96, 24, 8]),\n",
    "]\n",
    "store = []\n",
    "\n",
    "for (arch, layers) in archs_layers:\n",
    "    flops, params, fwd_lat = profile_model(arch, layers)\n",
    "    store.append([f\"{arch} {layers}\", params, flops, fwd_lat])\n",
    "clear_output()\n",
    "\n",
    "headers = [\"Model\", \"Params\", \"FLOPs/input\", \"μs/input\"]\n",
    "print(tabulate(store, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsnn_liam_py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
